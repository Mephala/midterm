{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import clear_output, display, HTML\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = np.matrix('4; 8; 16; 32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = np.matrix('2; 4; 8; 16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00294118]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.linalg.inv(A.T.dot(A))\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[680]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = A.T.dot(y)\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 2.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k*l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[23]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.matrix('2 3')\n",
    "test2 = np.matrix('4; 5')\n",
    "test*test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Data = [\n",
    "[0,0,-1.064],\n",
    "[0,1,-0.904],\n",
    "[0,5,0.532],\n",
    "[1,0,1.192],\n",
    "[1,2,0.010],\n",
    "[1,3,0.340],\n",
    "[2,0,4.417],\n",
    "[2,1,2.141],\n",
    "[2,2,-0.260],\n",
    "[2,3,1.039],\n",
    "[2,4,1.633],\n",
    "[2,5,0.031],\n",
    "[3,1,1.811],\n",
    "[3,3,0.619],\n",
    "[3,4,0.386],\n",
    "[3,5,0.577],\n",
    "[4,1,-1.467],\n",
    "[4,2,1.323],\n",
    "[4,4,0.516],\n",
    "[4,5,-0.949],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.064"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03953374633407225, 0.5618287945974195], [0.20775038211275687, 0.523326852756424], [0.5962244539792994, 0.6192207200076609], [0.3060222698171364, 0.46703830856495976], [0.27055969076737374, 0.9356732923800746]]\n",
      "-----------------\n",
      "[[0.20023565859050718, 0.712410485425875, 0.844904653371308, 0.9565553360559079, 0.7161565920748073, 0.6007645978391304], [0.5606050682413045, 0.10748292850848995, 0.7782498178351163, 0.9810123423296235, 0.6115628425929237, 0.9052230468439]]\n",
      "------------------\n",
      "[[-1.064, -0.904, [None], [None], [None], 0.532], [1.192, [None], 0.01, 0.34, [None], [None]], [4.417, 2.141, -0.26, 1.039, 1.633, 0.031], [[None], 1.811, [None], 0.619, 0.386, 0.577], [[None], -1.467, 1.323, [None], 0.516, -0.949]]\n"
     ]
    }
   ],
   "source": [
    "w = []\n",
    "h = []\n",
    "X = []\n",
    "def assign_random_parameters():\n",
    "    #create random w and h parameters\n",
    "    for i in range(5):\n",
    "        w.append([])    \n",
    "        for k in range(2):\n",
    "            w[i].append(random.random())\n",
    "    for k in range(2):\n",
    "        h.append([])    \n",
    "        for j in range(6):\n",
    "            h[k].append(random.random())\n",
    "    \n",
    "\n",
    "        \n",
    "#Constructing X 2D array for given values in data.\n",
    "\n",
    "for i in range(5):\n",
    "    X.append([])\n",
    "    for j in range(6):\n",
    "        X[i].append([])\n",
    "        X[i][j].append(None)\n",
    "        \n",
    "for element in Data:\n",
    "    X[element[0]][element[1]] = element[2]\n",
    "    \n",
    "\n",
    "    \n",
    "assign_random_parameters()       \n",
    "print(w)\n",
    "print('-----------------')\n",
    "print(h)\n",
    "print('------------------')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299.4068878836112\n",
      "1.452170289744923\n",
      "-1.064\n"
     ]
    }
   ],
   "source": [
    "def predict_X(i,j):\n",
    "    #print('pedicting for', i , ' and ' , j)\n",
    "    retval = (w[i][0]*h[0][j])+(w[i][1]*h[1][j])\n",
    "    #print('(',w[i][0] , 'x' ,h[0][j],')+(',w[i][1],'x',h[1][j],')=',retval )\n",
    "    return retval\n",
    "\n",
    "def calculate_error_single_element(i,j):\n",
    "    prediction = predict_X(i,j)\n",
    "    real = X[i][j]\n",
    "    error = prediction - real\n",
    "    return error**2\n",
    "\n",
    "\n",
    "def calculate_total_error(): #with square method\n",
    "    total_error = 0\n",
    "    for element in Data:\n",
    "        i = element[0]\n",
    "        j = element[1]\n",
    "        error = calculate_error_single_element(i,j)\n",
    "        total_error = total_error + error**2\n",
    "    return total_error\n",
    "\n",
    "#0,111056383 0,010663285\n",
    "#\n",
    "print(calculate_total_error())\n",
    "print(calculate_error_single_element(0,0))\n",
    "print(X[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimizing square of error\n",
    "\n",
    "$$\n",
    "x_{i,j} = w_{i,0} h_{0,j} + w_{i,1} h_{1,j} + \\epsilon_{i,j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\epsilon_{i,j} = X_{i,j} - w_{i,0} h_{0,j} - w_{i,1} h_{1,j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\epsilon_{i,j}^2 = ( X_{i,j} - w_{i,0} h_{0,j} - w_{i,1} h_{1,j} )^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\epsilon_{i,j}^2 = X_{i,j}^2 + w_{i,0}^2 h_{0,j}^2 + w_{i,1}^2 h_{1,j}^2 - 2X_{i,j} w_{i,0} h_{0,j} - 2X_{i,j} w_{i,1} h_{1,j} + 2 w_{i,0} h_{0,j} w_{i,1} h_{1,j}\n",
    "$$\n",
    "\n",
    "\n",
    "Minimizing the error function, we need to calculate partial derivative of the function with respect to parameters w and h.\n",
    "\n",
    "When k = 0:\n",
    "\n",
    "With respect to w:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\epsilon(i,j)}{\\partial w_{i,0}} = 2W_{i,0} h_{0,j}^2 - 2 X_{i,j} h_{0,j} + 2 h_{0,j} w_{i,1} h_{1,j}\n",
    "$$\n",
    "\n",
    "With respect to h:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\epsilon(i,j)}{\\partial h_{0,j}} = 2W_{i,0}^2 h_{0,j} - 2 X_{i,j} w_{i,0} + 2 w_{i,0} w_{i,1} h_{1,j}\n",
    "$$\n",
    "\n",
    "And when k = 1:\n",
    "\n",
    "With respect to w:\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\epsilon(i,j)}{\\partial w_{i,1}} = 2W_{i,1} h_{1,j}^2 - 2 X_{i,j} h_{1,j} + 2 w_{i,0} h_{0,j} h_{1,j}\n",
    "$$\n",
    "\n",
    "With respect to h:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\epsilon(i,j)}{\\partial h_{1,j}} = 2W_{i,1}^2 h_{1,j} - 2 X_{i,j} w_{i,1} + 2 w_{i,0} h_{0,j} w_{i,1}\n",
    "$$\n",
    "\n",
    "It turns out, when we are calculating derivative with respect to w or h ; the value of k changes the result.\n",
    "\n",
    "Also whan taking derivate of w, we are dependant on the j parameter as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0824205230585853\n",
      "0.2607770363752463\n"
     ]
    }
   ],
   "source": [
    "def deriv_W(i,j,k, X):\n",
    "    if k==0:\n",
    "        return (2*w[i][0]*h[0][j]**2)-(2*X*h[0][j])+(2*h[0][j]*w[i][1]*h[1][j])\n",
    "    else:\n",
    "        return (2*w[i][1]*h[1][j]**2)-(2*X*h[1][j])+(2*h[0][j]*w[i][0]*h[1][j])\n",
    "\n",
    "def deriv_H(i,j,k, X):\n",
    "    if k==0:\n",
    "        return (2*w[i][0]**2*h[0][j])-(2*X*w[i][0])+(2*w[i][0]*w[i][1]*h[1][j])\n",
    "    else:\n",
    "        return (2*w[i][1]**2*h[1][j])-(2*X*w[i][1])+(2*w[i][0]*h[0][j]*w[i][1])\n",
    "    \n",
    "print(deriv_W(0,0,0,-1.064))\n",
    "print(deriv_H(0,0,0,-1.064))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6644415373736069\n",
      "-0.547050164583501\n",
      "False\n",
      "False\n",
      "-0.6644415373736069\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 60000\n",
    "eta = 0.0000008363 # arbitrary low value\n",
    "i = 0\n",
    "j = 2\n",
    "k = 0\n",
    "print(w[i][k])\n",
    "print(h[k][j])\n",
    "print(type(X[i][j]) is float)\n",
    "print(X[i][j][0] is not None)\n",
    "if(type(X[i][j]) is float):\n",
    "    w[k][i] = w[k][i] - (eta*deriv_W(i,j,k,X[i][j]))\n",
    "print(w[i][k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2268249501443189\n",
      "0.5720955682358692\n",
      "491.42701620380745\n",
      "0.5720153795979268\n",
      "491.42310669728874\n"
     ]
    }
   ],
   "source": [
    "print(w[0][0])\n",
    "print(deriv_W(0,0,0,X[0][0]))\n",
    "print(calculate_total_error())\n",
    "w[0][0]= w[0][0] - 0.001\n",
    "print(deriv_W(0,0,0,X[0][0]))\n",
    "print(calculate_total_error())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49658646760694747\n",
      "0.4759396031899622\n",
      "--------------\n",
      "Prediction for given data:  0 , 0 , -1.0640000001278263\n",
      "Prediction for given data:  0 , 1 , -0.6269594542392218\n",
      "Prediction for given data:  0 , 5 , -0.29502667891127826\n",
      "Prediction for given data:  1 , 0 , 1.2001280005028474\n",
      "Prediction for given data:  1 , 2 , 0.0047068610885572515\n",
      "Prediction for given data:  1 , 3 , 0.3174417573662679\n",
      "Prediction for given data:  2 , 0 , 4.379888755443368\n",
      "Prediction for given data:  2 , 1 , 2.1070309980630118\n",
      "Prediction for given data:  2 , 2 , -0.23919844504059062\n",
      "Prediction for given data:  2 , 3 , 1.0744080067289783\n",
      "Prediction for given data:  2 , 4 , 1.6815891690019629\n",
      "Prediction for given data:  2 , 5 , 0.2252913881000252\n",
      "Prediction for given data:  3 , 1 , 1.8027957631429776\n",
      "Prediction for given data:  3 , 3 , 0.5993382852036643\n",
      "Prediction for given data:  3 , 4 , 0.4140634186896642\n",
      "Prediction for given data:  3 , 5 , 0.5508720405769952\n",
      "Prediction for given data:  4 , 1 , -1.529346455795255\n",
      "Prediction for given data:  4 , 2 , 1.3373756301055053\n",
      "Prediction for given data:  4 , 4 , 0.549460025590514\n",
      "Prediction for given data:  4 , 5 , -0.7820907155662924\n",
      "[[-0.5733689194913423, 0.27723951305031647, 0.9135549172485141, 0.6846151124519536, 0.3826030691672929, 0.8311193822368301, 0.6975943775229367, 0.03840416622769249, 0.21397838793388002, 0.7791044253558683, 0.4617461467788717, 0.11164755235514612, 0.8634327411362068, 0.8272886619420307, 0.3658375103315332, 0.4750045851400525, 0.6230580460137886, 0.06874972802372104], [0.3787449758694228, 0.31684617086324074, 0.08830078444550504, 0.5085549630617964, 0.05174504236122124, 0.8584162077670011, 0.032423650652953384, 0.515341625418799, 0.5797964063011396, 0.24994984643890528, 0.7832635982863456, 0.3453736845792932, 0.3416848179860785, 0.806681882723142, 0.2771082528747295, 0.705073273924507, 0.039162294325516545, 0.2628940465838847], [1.5030238945365788, 0.8725753551520445, 0.7717720597744677, 0.20143293127343542, 0.25182801221196494, 0.9376926696323913, 0.32250972107646625, 0.45932004124671943, 0.47565606777097436, 0.4203811389343084, 0.475517144900776, 0.7792245093479535, 0.6779670401797551, 0.7979930880478378, 0.4930309922451196, 0.08268780382613683, 0.3809284294117048, 0.0552265922434243], [1.4841260875809004, -0.09670887985897669, 0.5709267797480473, 0.7811972103500362, 0.11768282915655115, 0.008225459331959617, 0.5771080506410703, 0.28182460193530356, 0.21026934539053288, 0.1481824931488004, 0.025799615716601276, 0.7243364706375994, 0.9497930127520842, 0.007465677248169489, 0.7582334431201786, 0.01465009262727901, 0.3380123250442897, 0.8888612791818924], [-1.4331621482634145, 0.8232851196180496, 0.45816083952241005, 0.14909543366779943, 0.08829943009558072, 0.44926203846312107, 0.1598092278747163, 0.9524696360318754, 0.0991292526333456, 0.761625557252839, 0.05103130187236371, 0.7781779965564942, 0.7385201473512866, 0.46140943904682985, 0.01777762244429637, 0.6336022856252326, 0.18664615445334276, 0.6353316963531771], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "---------\n",
      "[[2.3366262274234257, 1.23360436219419, -0.5481961071890603, 0.4352170998886301, 0.36374473963668996, 0.34884500485828096, 0.9815826933199526, 0.6169504950109916, 0.3639522033985353, 0.6379994888693091, 0.6552670752295129, 0.4591896578525386, 0.81507483802074, 0.07252104994191866, 0.46927842742361714, 0.2502248213491225, 0.6501517001084935, 0.6384800727957436, 0.40224297863551706, 0.5390778598886349, 0.0571883628833082, 0.14130545606432565, 0.6733030447339505, 0.7810659267896789, 0.5406364481305523, 0.7992424572463795, 0.3867732983668303, 0.4573474480643901, 0.1816794873422911, 0.5931932319962171, 0.5601579839869363, 0.7295670299735358, 0.43749528371376456, 0.2661935539165239, 0.6268814735878135, 0.49311780655508197, 0.7130929016152185, 0.19781721013150766, 0.167301943994138, 0.8449973878895449, 0.7950235206425372, 0.7049037759001734, 0.8455453707424341, 0.23083019048452502, 0.728515452072315, 0.47257045296695666, 0.6045095761452631, 0.12448483116683795, 0.2919530118425876, 0.3299624735494351, 0.007013506489725652, 0.18455737982247777, 0.7596167039451746, 0.09858138246837533], [0.9946232126552208, 0.2898250148682248, 0.6701465947942232, 0.48163898258646504, 1.300600718454032, -0.3426993301221468, 0.6953223988051043, 0.6808733925991055, 0.7074431542679168, 0.7983128646619038, 0.23953343089555468, 0.14258710809565645, 0.9516237389768182, 0.0172786304555288, 0.9659527605041937, 0.8452089465871797, 0.3818857077831669, 0.6637238839238228, 0.1395051435705721, 0.3166467903512876, 0.7818595173672167, 0.3833663014945524, 0.7190875967178194, 0.42481349364302357, 0.2890297248594764, 0.3534295355893703, 0.984649775171951, 0.3688375234548871, 0.35562638456878004, 0.22213475239569724, 0.6438357630539544, 0.6619629456265754, 0.469055247934848, 0.8634239892437393, 0.331257399019264, 0.0868862013998356, 0.27426965948784954, 0.8248438015517241, 0.2401852361254857, 0.8513267047027555, 0.6670827523079955, 0.021259355715288142, 0.42805177533496763, 0.030364619870487775, 0.9778495760572042, 0.9384070397827234, 0.46058674368101393, 0.1983330293450476, 0.6277693945998754, 0.975205252537951, 0.7502357701138317, 0.24763312049295771, 0.1446810414950046, 0.9355366659349841], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
     ]
    }
   ],
   "source": [
    "print(calculate_total_error())\n",
    "start_error = calculate_total_error()\n",
    "for k in range(2):\n",
    "    for i in range(5):\n",
    "        for j in range(6):\n",
    "            current_error = calculate_total_error()\n",
    "            while current_error <= start_error:\n",
    "                start_error = current_error\n",
    "                if(type(X[i][j]) is float): # Some i,j values does not exist in Data\n",
    "                    w[i][k] = w[i][k] - (eta*deriv_W(i,j,k,X[i][j]))\n",
    "                    h[k][j] = h[k][j] - (eta*deriv_H(i,j,k,X[i][j]))\n",
    "                    current_error = calculate_total_error()\n",
    "                else:\n",
    "                    break\n",
    "                    \n",
    "print(calculate_total_error()) # Must show low error\n",
    "print('--------------')\n",
    "for element in Data:\n",
    "    i = element[0]\n",
    "    j = element[1]\n",
    "    prediction = predict_X(i,j)\n",
    "    print('Prediction for given data: ', i , ',' , j, ',' , prediction)\n",
    "print(w)\n",
    "print('---------')\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 2 , 0.5001097252614297\n",
      "0 , 3 , -0.116010601308978\n",
      "0 , 4 , 0.15201798152093907\n",
      "1 , 1 , 0.559051400573032\n",
      "1 , 4 , 0.5498568501004675\n",
      "1 , 5 , 0.023540322440618433\n",
      "3 , 0 , 3.371659044267225\n",
      "3 , 2 , -0.8784012703134368\n",
      "4 , 0 , -2.529905773177052\n",
      "4 , 3 , -0.2272104664459486\n"
     ]
    }
   ],
   "source": [
    "test_indices = [[0,2],\n",
    "[0,3],\n",
    "[0,4],\n",
    "[1,1],\n",
    "[1,4],\n",
    "[1,5],\n",
    "[3,0],\n",
    "[3,2],\n",
    "[4,0],\n",
    "[4,3]]\n",
    "\n",
    "predicted_model = []\n",
    "\n",
    "for indice in test_indices:\n",
    "    i = indice[0]\n",
    "    j = indice[1]\n",
    "    prediction = predict_X(i,j)\n",
    "    print(i,',',j,',',prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
